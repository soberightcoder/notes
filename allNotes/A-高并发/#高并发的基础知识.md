#高并发的基础知识

1、基础概念

####**tcp四元组**    ip是2元组的源地址 和目的地址；

所谓tcp连接是由一个四元组组成，如下所示：

本地ip地址+本地端口+远端ip地址+远端端口

一个设备不管是服务端还是客户端，所支持的最大tcp连接数，如果不考虑cpu及内存消耗，只和这四个因素有关；

单tcp连接占用内存

https://blog.csdn.net/sinat_41832255/article/details/80048580

请参考如上连接描述，这里不再过多描述；

 

####**2、服务端支持最大多少tcp连接？**
在不考虑服务端cpu和内存消耗情况下，一个服务端web程序，不论是netty、tomcat、jetty、undertow，还是其他语言其他框架的web应用，

其首先在四元组中有两个确定参数，即：本地主机ip+本地主机监听端口，

变化本分为：客户端ip地址，有多少个客户端就有多少个端口，因此这里可以理解为很大；

第二个参数是客户端发起端口，通常linux默认情况下单ip支持的端口是65536个，除去前1024个端口外，其他均可以作为客户端发起端口，因此这里的个数是6w以上；

总结下来：一个web应用，监听某个端口，在不考虑内存、cpu及linux文件数目限制的前提，其可以建立的web连接是可以很大的，具体大于多少？肯定大于百万，甚至千万。

####**3、客户端连接同一服务端web应用最大支持多少个tcp连接？**
上两节已经提到，tcp连接是一个四元组，对于连接同一个服务端 的web，其远端ip及远端端口已经固定，唯一的变量是本地ip和本地端口，

通常情况下由于本地ip也是固定的，因此唯一的变量成为发起连接的端口号，由于一个ip linux最多支持65536个端口，其中前1024个端口保留，剩下来了6w多个端口，

也就是说，如果客户端连接最多支持向统一服务端web应用的统一端口建立6w多个连接。

当然这里也有几个注意事项：

客户端连接同一服务端web应用的相同监听端口最大支持6w多个端口，这里的前提是linux调整tcp连接参数，默认情况下这个分配范围并不是1024-65536，这个值需要修改；
客户端如果可以在发起连接的时候改变本地ip地址，每增加一个ip，其最大连接能力也因此增加6w多个，这里有许多做法，比如配置多网卡、配置子接口等等，请查看其他资料；
微服务化日益流行的当下，通常使用nginx做反向代理，将请求hash到不同服务端，对于需要支持百万连接的服务，如果只有一个nginx不配置多个ip或者开启相关配置（这里nginx是否支持向同一服务端口以不同ip发起连接，本人并没有研究，有待确认），最多也就是支持像一个服务同时连接6w多个tcp连接；







```
并发总数：max_clients = worker_processes * worker_connections 
nginx做反向代理的情况下，max_clients = （worker_processes * worker_connections）/ 4   # 一般都除以4, 经验所得。

因并发受IO的约束，worker_connections 值的设置跟物理内存大小有关，max_clients 的值必须小于操作系统理论情况下可以打开的最大文件数。

而操作系统可以打开的最大文件数和内存大小成正比，查看32G内存的机器上，理论情况下，可以打开的最大文件数： 这是总的打开数目；
#cat /proc/sys/fs/file-max
3262366

当max_clients < `cat /proc/sys/fs/file-max` 的值时，这样在操作系统可以承受的范围内。

worker_connections 的值需根据 worker_processes 进程数和系统可以打开的最大文件总数 适当地进行设置，也就是要根据系统的CPU和内存进行配置
```



**worker_processes 4; worker_cpu_affinity 0001 0010 0100 1000;**







1、worker_cpu_affinity配置最好是能写上
我这里服务器多数是双核超线程，相当于4cpu，我一般开8进程，所以这个配置就是这样：
worker_cpu_affinity 0001 0100 1000 0010 0001 0100 1000 0010;

另，worker_cpu_affinity不是什么时候都能用的，
我没有认真研究并罗列所有情况，只知道2.4内核的机器用不了，
如果用不了的话，那么最好是加大worker_processes进程数，这样分配cpu就会平均一点啦，
如果不平均只好多重启几下。

2、worker_rlimit_nofile配置要和系统的单进程打开文件数一致，千万不要再画蛇添足地除以worker_processes。
我现在在linux 2.6内核下开启文件打开数为65535，worker_rlimit_nofile就相应应该填写65535。

这是因为nginx调度时分配请求到进程并不是那么的均衡，所以假如填写10240，
总并发量达到3-4万时就有进程可能超过10240了，这时会返回502错误。



**ulimit -a 默认单个进程的文件打开数目；**

**系统的总的最大的打开文件数目；**

cat /proc/sys/fs/file-max
3262366



-n  requests  请求数

-c concurrent  并发数；-c                                                                                                                                                                                                                                        

**-s  timeout**  超时默认是30s  Maximum number of seconds to wait before the socket times out. Default is 30 seconds



**-t Maximum number of seconds to spend for benchmarking.** This implies a -n  50000  internally.
              Use this to benchmark the server within a fixed total amount of time. Per default there is
              no timelimit.

用于基准测试的最大秒数。限制时间 在多少s内的请求数目；



-t 时间限制
               用于基准测试的最大秒数。 这意味着 -n 50000 内部。
               使用它在固定的总时间内对服务器进行基准测试。 默认情况下有
               没有时间限制。